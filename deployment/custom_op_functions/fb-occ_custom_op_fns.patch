From 4cc03d07d65d012503c2a24a40acc3141b9f333f Mon Sep 17 00:00:00 2001
From: "John Yang (SW-TEGRA)" <johnyang@nvidia.com>
Date: Fri, 20 Dec 2024 21:09:55 -0800
Subject: [PATCH] fb-occ_custom_op_fns

---
 det2trt/models/functions/__init__.py          |  16 +--
 det2trt/models/functions/bev_pool_v2.py       |  19 +--
 det2trt/models/functions/grid_sampler.py      |   2 +-
 .../functions/multi_scale_deformable_attn.py  | 121 ++++--------------
 4 files changed, 41 insertions(+), 117 deletions(-)

diff --git a/det2trt/models/functions/__init__.py b/det2trt/models/functions/__init__.py
index 479b6b6..56f668d 100644
--- a/det2trt/models/functions/__init__.py
+++ b/det2trt/models/functions/__init__.py
@@ -1,17 +1,17 @@
-from .grid_sampler import grid_sampler, grid_sampler2
-from .multi_scale_deformable_attn import (
+from deployment.custom_op_functions.grid_sampler import grid_sampler, grid_sampler2
+from deployment.custom_op_functions.multi_scale_deformable_attn import (
     multi_scale_deformable_attn,
     multi_scale_deformable_attn2,
 )
-from .modulated_deformable_conv2d import (
+from deployment.custom_op_functions.modulated_deformable_conv2d import (
     modulated_deformable_conv2d,
     modulated_deformable_conv2d2,
 )
-from .rotate import rotate, rotate2
-from .inverse import inverse
-from .bev_pool_v2 import bev_pool_v2, bev_pool_v2_2
-from .multi_head_attn import qkv, qkv2
-from ..utils.register import TRT_FUNCTIONS
+from deployment.custom_op_functions.rotate import rotate, rotate2
+from deployment.custom_op_functions.inverse import inverse
+from deployment.custom_op_functions.bev_pool_v2 import bev_pool_v2, bev_pool_v2_2
+from deployment.custom_op_functions.multi_head_attn import qkv, qkv2
+from deployment.utils.trt_register import TRT_FUNCTIONS
 
 
 TRT_FUNCTIONS.register_module(module=grid_sampler)
diff --git a/det2trt/models/functions/bev_pool_v2.py b/det2trt/models/functions/bev_pool_v2.py
index 1a95bcc..6f4f079 100644
--- a/det2trt/models/functions/bev_pool_v2.py
+++ b/det2trt/models/functions/bev_pool_v2.py
@@ -1,6 +1,5 @@
 from torch.autograd import Function
-from third_party.bev_mmdet3d.ops.bev_pool_v2 import bev_pool_v2_gpu
-
+from mmdet3d.ops.bev_pool_v2 import bev_pool_v2_gpu
 
 class _BEVPoolV2(Function):
     @staticmethod
@@ -43,11 +42,9 @@ class _BEVPoolV2(Function):
         out_width,
     ):
         """run forward."""
-        feat = feat.unsqueeze(0)
-        depth = depth.unsqueeze(0)
         bev_feat_shape = (
             depth.shape[0],
-            1,
+            8,
             out_height,
             out_width,
             feat.shape[-1],
@@ -62,8 +59,6 @@ class _BEVPoolV2(Function):
             interval_starts,
             interval_lengths,
         )
-        bev_feat = bev_feat.squeeze(2)
-        bev_feat = bev_feat.permute(0, 2, 3, 1)
         return bev_feat
 
     @staticmethod
@@ -111,8 +106,8 @@ def bev_pool_v2(
     ranks_bev,
     interval_starts,
     interval_lengths,
-    out_height=128,
-    out_width=128,
+    out_height=100,
+    out_width=100,
 ):
     return _bev_pool_v2(
         depth,  # N,D,H,W
@@ -135,8 +130,8 @@ def bev_pool_v2_2(
     ranks_bev,
     interval_starts,
     interval_lengths,
-    out_height=128,
-    out_width=128,
+    out_height=100,
+    out_width=100,
 ):
     return _bev_pool_v2_2(
         depth,  # N,D,H,W
@@ -148,4 +143,4 @@ def bev_pool_v2_2(
         interval_lengths.int(),
         out_height,
         out_width,
-    )
+    )
\ No newline at end of file
diff --git a/det2trt/models/functions/grid_sampler.py b/det2trt/models/functions/grid_sampler.py
index 0c7e63f..8a68c71 100644
--- a/det2trt/models/functions/grid_sampler.py
+++ b/det2trt/models/functions/grid_sampler.py
@@ -76,7 +76,7 @@ class _GridSampler3D(Function):
         padding_mode: _int,
         align_corners: _bool,
     ):
-        grid = grid.permute(0, 2, 3, 4, 1)
+        grid = grid.permute(0, 2, 3, 4, 1)  
         grid_ = grid / 10
         output = torch.ops.aten.grid_sampler(
             input, grid_, interpolation_mode, padding_mode, align_corners
diff --git a/det2trt/models/functions/multi_scale_deformable_attn.py b/det2trt/models/functions/multi_scale_deformable_attn.py
index 36db587..3e88a99 100644
--- a/det2trt/models/functions/multi_scale_deformable_attn.py
+++ b/det2trt/models/functions/multi_scale_deformable_attn.py
@@ -13,16 +13,16 @@ class _MultiScaleDeformableAttnFunction(Function):
         g,
         value,
         value_spatial_shapes,
-        reference_points,
-        sampling_offsets,
+        value_level_start_index, 
+        sampling_locations,
         attention_weights,
     ):
         return g.op(
             "MultiScaleDeformableAttnTRT",
             value,
             value_spatial_shapes,
-            reference_points,
-            sampling_offsets,
+            value_level_start_index, 
+            sampling_locations,
             attention_weights,
         )
 
@@ -31,88 +31,20 @@ class _MultiScaleDeformableAttnFunction(Function):
         ctx,
         value,
         value_spatial_shapes,
-        reference_points,
-        sampling_offsets,
+        value_level_start_index, 
+        sampling_locations,
         attention_weights,
     ):
-        """GPU version of multi-scale deformable attention.
-
-        Args:
-            value (Tensor): The value has shape
-                (bs, mum_heads, embed_dims//num_heads, num_keys)
-            value_spatial_shapes (Tensor): Spatial shape of
-                each feature map, has shape (num_levels, 2),
-                last dimension 2 represent (h, w)
-            reference_points (Tensor): The reference points.
-            sampling_offsets (Tensor): The offset of sampling points,
-                has shape
-                (bs, num_heads, num_queries, num_levels*num_points*2),
-                the last dimension 2 represent (x, y).
-            attention_weights (Tensor): The weight of sampling points used
-                when calculate the attention, has shape
-                (bs, num_heads, num_queries, num_levels*num_points).
-
-        Returns:
-            Tensor: has shape (bs, embed_dims, num_queries)
-        """
-        num_heads, channel = value.shape[2:]
-        num_level = value_spatial_shapes.shape[0]
-        bs, num_queries = reference_points.shape[:2]
-
-        points_per_group = torch.div(
-            reference_points.shape[-1], 2, rounding_mode="floor"
-        )
-        sampling_offsets = sampling_offsets.view(
-            bs, num_queries, num_heads, num_level, -1, points_per_group, 2,
-        )
-        dim = sampling_offsets.shape[4] * num_level * 2 * points_per_group
-        offset_normalizer = torch.stack(
-            [value_spatial_shapes[..., 1], value_spatial_shapes[..., 0]], -1
-        )
-        sampling_locations = reference_points.view(
-            bs, num_queries, 1, 1, 1, -1, 2
-        ) + sampling_offsets / offset_normalizer.view(1, 1, 1, -1, 1, 1, 2)
-        sampling_locations = sampling_locations.view(
-            bs,
-            num_queries,
-            num_heads,
-            num_level,
-            torch.div(dim, num_level * 2, rounding_mode="floor"),
-            2,
-        )
-        attention_weights = attention_weights.view(
-            -1, num_level * torch.div(dim, num_level * 2, rounding_mode="floor")
-        ).softmax(-1)
-        attention_weights = attention_weights.view(
-            bs,
-            num_queries,
-            num_heads,
-            num_level,
-            torch.div(dim, num_level * 2, rounding_mode="floor"),
-        )
         im2col_step = value.shape[0]
         ctx.im2col_step = im2col_step
-
-        ctx.fp16 = False
-        if value.dtype == torch.float16:
-            ctx.fp16 = True
-            value = value.float()
-            sampling_locations = sampling_locations.float()
-            attention_weights = attention_weights.float()
-
-        value_level_start_index = torch.zeros_like(value_spatial_shapes[:, 0])
-        value_level_start_index[1:] = torch.cumsum(
-            value_spatial_shapes[:, 0] * value_spatial_shapes[:, 1], dim=0
-        )[:-1]
-
         output = ext_module.ms_deform_attn_forward(
-            value,
-            value_spatial_shapes,
-            value_level_start_index,
-            sampling_locations,
-            attention_weights,
-            im2col_step=ctx.im2col_step,
-        ).view(bs, num_queries, num_heads, channel)
+            value, 
+            value_spatial_shapes, 
+            value_level_start_index, 
+            sampling_locations, 
+            attention_weights, 
+            im2col_step=ctx.im2col_step)
+        
         ctx.save_for_backward(
             value,
             value_spatial_shapes,
@@ -120,27 +52,24 @@ class _MultiScaleDeformableAttnFunction(Function):
             sampling_locations,
             attention_weights,
         )
-        return output.half() if ctx.fp16 else output
+        return output
 
 
 class _MultiScaleDeformableAttnFunction2(_MultiScaleDeformableAttnFunction):
     @staticmethod
-    def symbolic(
-        g,
-        value,
-        value_spatial_shapes,
-        reference_points,
-        sampling_offsets,
-        attention_weights,
-    ):
+    def symbolic(g, 
+                 value, 
+                 value_spatial_shapes,
+                 level_start_index, 
+                 sampling_locations, 
+                 attention_weights):
         return g.op(
             "MultiScaleDeformableAttnTRT2",
-            value,
+            value, 
             value_spatial_shapes,
-            reference_points,
-            sampling_offsets,
-            attention_weights,
-        )
+            level_start_index, 
+            sampling_locations, 
+            attention_weights)
 
 
 _multi_scale_deformable_attn_gpu = _MultiScaleDeformableAttnFunction.apply
@@ -214,4 +143,4 @@ def multi_scale_deformable_attn2(
         reference_points,
         sampling_offsets,
         attention_weights,
-    )
+    )
\ No newline at end of file
-- 
2.25.1

